{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis ML way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Given to you short review of some movies. The reviews could talk bad or good about the movie. We can identify the sentiment of the text by looking/reading the words in the sentence. How can we make a machine/system understand the sentiment in the text.\n",
    "\n",
    "#One way is the ML way. There is a ground truth that is created for some corpus i.e  we have both postive and negative reviews that are tagged with their respective class. This forms the base and the algorithm is trained on this data (after converting this to structured form) and depending on the words used the classification is done (Machine/system tries to obtain a pattern from data).\n",
    "\n",
    "#Another way is dictionary approach, where we create a dictionary of positive and negative words and explicitly state that these words are positive or negative. We can then count the number of positive and negative words in the sentence and give a score. If the score is positive then its positive else its negative.\n",
    "\n",
    "#In either cases, there is manual work involved (creating ground truth in case 1 or creating the dictionary in case 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = open(\"short_reviews/positive.txt\",\"r\")   # \"r\" is for reading\n",
    "short_pos = f1.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth . \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_pos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(short_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_pos=[re.sub(\"\\n\",\"\",i)for i in short_pos]\n",
    "x_short_pos=short_pos[:1000]\n",
    "f2 = open(\"short_reviews/negative.txt\",\"r\")\n",
    "short_neg = f2.readlines()\n",
    "short_neg=[re.sub(\"\\n\",\"\",i)for i in short_neg]\n",
    "x_short_neg=short_neg[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth . '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_short_pos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(short_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer(stop_words='english',lowercase=True,\n",
    "                   strip_accents='unicode',decode_error='ignore')\n",
    "data=x_short_pos+x_short_neg\n",
    "tdm = cv.fit_transform(data)\n",
    "Mat = tdm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000L, 7402L)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Mat = pd.DataFrame(Mat)\n",
    "Mat['type'] = ['pos']*1000+['neg']*1000\n",
    "Mat = pd.DataFrame(Mat)\n",
    "Mat = Mat.sample(frac = 1,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7393</th>\n",
       "      <th>7394</th>\n",
       "      <th>7395</th>\n",
       "      <th>7396</th>\n",
       "      <th>7397</th>\n",
       "      <th>7398</th>\n",
       "      <th>7399</th>\n",
       "      <th>7400</th>\n",
       "      <th>7401</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 7403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...   7393  7394  7395  7396  7397  7398  \\\n",
       "1748  0  0  0  0  0  0  0  0  0  0  ...      0     0     0     0     0     0   \n",
       "934   0  0  0  0  0  0  0  0  0  0  ...      0     0     0     0     0     0   \n",
       "\n",
       "      7399  7400  7401  type  \n",
       "1748     0     0     0   neg  \n",
       "934      0     0     0   pos  \n",
       "\n",
       "[2 rows x 7403 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train = Mat.iloc[:1800]\n",
    "test = Mat.iloc[1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "X=train.ix[:,:-1].as_matrix()\n",
    "Y=train.ix[:,-1].as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=test.ix[:,:-1].as_matrix()\n",
    "true=test.ix[:,-1].as_matrix()\n",
    "pred=logreg.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59, 38],\n",
       "       [33, 70]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test.ix[:,-1],pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.64      0.61      0.62        97\n",
      "        pos       0.65      0.68      0.66       103\n",
      "\n",
      "avg / total       0.64      0.65      0.64       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticRegression.predict_proba of LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'pos', 'pos',\n",
       "       'neg', 'neg', 'neg', 'neg', 'pos', 'neg', 'neg', 'pos', 'pos',\n",
       "       'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg',\n",
       "       'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg',\n",
       "       'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg',\n",
       "       'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos',\n",
       "       'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'pos', 'neg', 'pos',\n",
       "       'neg', 'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg',\n",
       "       'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'neg', 'neg', 'pos',\n",
       "       'neg', 'pos', 'neg', 'neg', 'pos', 'pos', 'neg', 'pos', 'neg',\n",
       "       'pos', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'pos',\n",
       "       'pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg',\n",
       "       'neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'pos', 'pos', 'neg',\n",
       "       'pos', 'neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'neg', 'neg',\n",
       "       'neg', 'neg', 'pos', 'neg', 'pos', 'pos', 'neg', 'neg', 'neg',\n",
       "       'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos',\n",
       "       'neg', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg', 'pos',\n",
       "       'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg', 'neg',\n",
       "       'pos', 'neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'neg', 'pos',\n",
       "       'neg', 'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'neg', 'pos',\n",
       "       'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'pos',\n",
       "       'neg', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg',\n",
       "       'neg', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg',\n",
       "       'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg',\n",
       "       'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg',\n",
       "       'neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg', 'neg', 'pos',\n",
       "       'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'neg', 'neg', 'pos',\n",
       "       'pos', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'neg',\n",
       "       'pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos',\n",
       "       'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg',\n",
       "       'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos',\n",
       "       'pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg',\n",
       "       'neg', 'pos', 'neg', 'pos', 'neg', 'neg', 'neg', 'pos', 'pos',\n",
       "       'neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'neg',\n",
       "       'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg',\n",
       "       'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'neg', 'neg',\n",
       "       'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'neg',\n",
       "       'pos', 'neg', 'neg', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos',\n",
       "       'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos',\n",
       "       'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos',\n",
       "       'pos', 'neg', 'neg', 'neg', 'pos', 'pos', 'neg', 'neg', 'neg',\n",
       "       'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg',\n",
       "       'neg', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'neg', 'pos',\n",
       "       'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos',\n",
       "       'neg', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with any other classification model and check if you can improve the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.67      0.65      0.66        97\n",
      "        pos       0.68      0.70      0.69       103\n",
      "\n",
      "avg / total       0.67      0.68      0.67       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train.ix[:,:-1],train.ix[:,-1])\n",
    "A=classifier.predict(test.ix[:,:-1])\n",
    "confusion_matrix(test.ix[:,-1],A)\n",
    "\n",
    "print(classification_report(test.ix[:,-1], A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg', 'neg',\n",
       "       'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg', 'neg',\n",
       "       'pos', 'pos', 'neg', 'neg', 'pos', 'pos', 'neg', 'pos', 'neg',\n",
       "       'neg', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos',\n",
       "       'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg', 'pos',\n",
       "       'pos', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'pos',\n",
       "       'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'pos', 'pos', 'pos',\n",
       "       'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg',\n",
       "       'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'pos',\n",
       "       'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos', 'neg',\n",
       "       'neg', 'pos', 'neg', 'pos', 'neg', 'neg', 'pos', 'neg', 'pos',\n",
       "       'neg', 'pos', 'neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'pos',\n",
       "       'neg', 'pos', 'neg', 'pos', 'neg', 'neg', 'pos', 'pos', 'neg',\n",
       "       'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg', 'pos',\n",
       "       'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'neg',\n",
       "       'pos', 'neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'pos', 'pos',\n",
       "       'pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg',\n",
       "       'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos',\n",
       "       'neg', 'neg', 'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'neg',\n",
       "       'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg',\n",
       "       'neg', 'neg', 'pos', 'neg', 'neg', 'pos', 'pos', 'neg', 'neg',\n",
       "       'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos',\n",
       "       'neg', 'pos'], \n",
       "      dtype='|S3')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#What else could be done to improve the accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Solution: There could be some common words in both positive and negative reviews.\n",
    "    To avoid such words we can consider only adjectives to solve the problem and check if the accuracies improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=[1,2,3]\n",
    "B=[4,5]\n",
    "A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
