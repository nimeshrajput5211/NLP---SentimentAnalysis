{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Read the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_csv(\"SMSSpamCollection.csv\", header=None)\n",
    "input_data.head()\n",
    "input_data.columns = [\"text\"]\n",
    "\n",
    "col1 = input_data.text.str.split(\"\\t\").str[0]  ## Extract Target Variable\n",
    "df_col1 = pd.DataFrame(col1) ## Convert Into data frame\n",
    "df_col1.columns = [\"type\"] ### Change the column name\n",
    "df_col1.shape ## Checking The total no of records\n",
    "\n",
    "\n",
    "col2 = input_data.text.str.split(\"\\t\").str[1] ## Content column\n",
    "df_col2 = pd.DataFrame(col2)## Convert Into data frame\n",
    "df_col2.shape\n",
    "\n",
    "## Add temporary columns ID for merging the two data frame\n",
    "df_col1[\"id\"] = df_col1.index \n",
    "df_col2[\"id\"] = df_col2.index\n",
    "new_data = df_col1.merge(df_col2)\n",
    "new_data\n",
    "\n",
    "## Drop The Temporary column from the new data frame\n",
    "new_data.drop(new_data.columns[1], axis = 1, inplace = True)\n",
    "new_data.head()\n",
    "\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Go until jurong point\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    U dun say so early hor... U c already then say...\n",
       "4                     Nah I don't think he goes to usf\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = new_data[\"text\"]\n",
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = text_data.tolist()\n",
    "\n",
    "## Preprocessing Text Mining \n",
    "\n",
    "for i in range(len(text1)):\n",
    "    text1[i] = re.sub(r'\\s+', ' ', text1[i])\n",
    "    text1[i] = re.sub('[\\d]', ' ', text1[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(ngram_range = (1,1), stop_words = 'english')\n",
    "tfidf = tfidf_vector.fit_transform(text1)\n",
    "tfidf.shape\n",
    "\n",
    "dense_mat = tfidf.todense()\n",
    "dense_mat\n",
    "a = pd.DataFrame(dense_mat, columns= tfidf_vector.get_feature_names())\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4827\n",
      "spam     747\n",
      "Name: type, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      1.00      0.99      4827\n",
      "       spam       1.00      0.84      0.91       747\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classification = MultinomialNB().fit(tfidf, new_data[\"type\"])\n",
    "pred = classification.predict(tfidf)\n",
    "print new_data[\"type\"].value_counts()\n",
    "\n",
    "## Build Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "prediction = confusion_matrix(new_data[\"type\"], pred)\n",
    "prediction\n",
    "\n",
    "print (classification_report(new_data[\"type\"], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.96      1.00      0.98      4827\n",
      "       spam       0.99      0.74      0.85       747\n",
      "\n",
      "avg / total       0.97      0.96      0.96      5574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "log_model = logreg.fit(tfidf, new_data[\"type\"])\n",
    "pred_log = log_model.predict(tfidf)\n",
    "print(classification_report(new_data[\"type\"], pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Spliting The Data into train and test, on top of that we build Naive Bayes and Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dense_mat, new_data[\"type\"],test_size = 0.3, random_state = 5211)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logreg_train = linear_model.LogisticRegression()\n",
    "clr_log = logreg_train.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Predict on train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.95      1.00      0.98      3364\n",
      "       spam       0.99      0.69      0.81       537\n",
      "\n",
      "avg / total       0.96      0.96      0.95      3901\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.94      1.00      0.97      1463\n",
      "       spam       0.99      0.57      0.72       210\n",
      "\n",
      "avg / total       0.95      0.95      0.94      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train = clr_log.predict(x_train)\n",
    "pred_test = clr_log.predict(x_test)\n",
    "\n",
    "print(classification_report(y_train, pred_train))\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build Naive Bayes Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_model = MultinomialNB().fit(x_train, y_train)\n",
    "naive_train = naive_model.predict(x_train)\n",
    "naive_test = naive_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Predict On Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.98      3364\n",
      "       spam       1.00      0.79      0.88       537\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3901\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.96      1.00      0.98      1463\n",
      "       spam       1.00      0.69      0.81       210\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, naive_train))\n",
    "print(classification_report(y_test, naive_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
